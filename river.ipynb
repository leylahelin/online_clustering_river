{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1CBY8kD-Hor"
      },
      "source": [
        "<ul>\n",
        "<li><a href=\"#introduction\">1 - Online Machine Learning</a></li>\n",
        "<li><a href=\"#river\">2 - River </a></li>\n",
        "    <ul>\n",
        "        <li><a href=\"#cluster\">2.1 Clustering</a></li>\n",
        "        <li><a href=\"#drift\">2.2 Concept Drift</a></li>\n",
        "                <li><a href=\"#pipe\">2.3 Build Pipeline</a></li>\n",
        "    </ul>\n",
        "\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoIT2KdE-TdT"
      },
      "source": [
        "<a id='introduction'></a>\n",
        "\n",
        "**1. Online Machine Learning**\n",
        "\n",
        "Online machine learning processes one data at a time which also means model is updated as data come in real or near-real time, on the other hand there is offline machine learning that works on batch or historical data. There is some platforms that allows us to online computation like:\n",
        "\n",
        "* Apache Kafka for database\n",
        "* Apache Flink for analytic \n",
        "* River for machine learning\n",
        "* Parent Packages of River\n",
        "  * Creme\n",
        "  * Scikit-Multiflow\n",
        "\n",
        "> Limitation of online machine learning\n",
        "  *   Cant do vectoriztion\n",
        "  *   less memory\n",
        "  *   less unknown so limited resource avalaible in community and lack of good examples\n",
        "  *   if there is historical or given dataset then batch processing more meaningful\n",
        "  * may not be avaliable for some ml algorithms\n",
        "\n",
        "\n",
        "> Goodness of online machine learning\n",
        "\n",
        "  * requires low computational power\n",
        "  * feedback is fast (for ex. recommendation)\n",
        "  * non static learning\n",
        "  * dont have to revisit past data\n",
        "  * may able to identify and detect concept drift\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKpYOpNpH1pt"
      },
      "source": [
        "<a id='river'></a>\n",
        "\n",
        "**2. River**\n",
        "\n",
        "River is python libraray that allows us to process online machine learning applications. River datasets are python dicts rather than more sophisticated types like nump array or pandas dataframe.\n",
        "\n",
        "> Some Useful modules:\n",
        "  * Datasets\n",
        "  * Models\n",
        "  * Pipelines\n",
        "  * Cluster\n",
        "  * Drift\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import river\n",
        "import pandas as pd\n",
        "import river\n",
        "from river import cluster\n",
        "from river import stream\n",
        "from river import datasets\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "from river.datasets import synth\n",
        "import numpy as np\n",
        "from river.drift import ADWIN\n",
        "from river import metrics\n",
        "from river import drift\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zgyfipEyQoL4"
      },
      "outputs": [],
      "source": [
        "def get_all_attributes(package):\n",
        "    subpackages = []\n",
        "    submodules = []\n",
        "    for i in dir(package):\n",
        "        if str(i) not in [\"__all__\", \"__builtins__\", \"__cached__\", \"__doc__\", \"__file__\", \"__loader__\", \"__name__\", \"__package__\", \"__path__\", \"__pdoc__\", \"__spec__\", \"__version__\"]:\n",
        "            subpackages.append(i)\n",
        "            res = [j for j in dir(eval(\"river.{}\".format(i)))]\n",
        "            submodules.append(res)\n",
        "    df = pd.DataFrame(submodules)\n",
        "    df = df.T\n",
        "    df.columns = subpackages\n",
        "    res_df = df.dropna()\n",
        "    return res_df\n",
        "river_df = get_all_attributes(river)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT1OrGlE3G8x",
        "outputId": "0aacbd91-fff6-4809-fe3c-e0f5752c1b6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['base', 'cluster', 'datasets', 'stats', 'stream', 'utils'], dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "river_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "TEX5sb4uRDWa",
        "outputId": "862335bd-4ef7-482a-d5ec-83518a7c79ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster</th>\n",
              "      <th>datasets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CluStream</td>\n",
              "      <td>AirlinePassengers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DBSTREAM</td>\n",
              "      <td>Bananas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DenStream</td>\n",
              "      <td>Bikes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KMeans</td>\n",
              "      <td>ChickWeights</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>STREAMKMeans</td>\n",
              "      <td>CreditCard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TextClust</td>\n",
              "      <td>Elec2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>__all__</td>\n",
              "      <td>HTTP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>__builtins__</td>\n",
              "      <td>Higgs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>__cached__</td>\n",
              "      <td>ImageSegments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>__doc__</td>\n",
              "      <td>Insects</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>__file__</td>\n",
              "      <td>Keystroke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>__loader__</td>\n",
              "      <td>MaliciousURL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>__name__</td>\n",
              "      <td>MovieLens100K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>__package__</td>\n",
              "      <td>Music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>__path__</td>\n",
              "      <td>Phishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>__spec__</td>\n",
              "      <td>Restaurants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>clustream</td>\n",
              "      <td>SMSSpam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>dbstream</td>\n",
              "      <td>SMTP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>denstream</td>\n",
              "      <td>SolarFlare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>k_means</td>\n",
              "      <td>TREC07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>streamkmeans</td>\n",
              "      <td>Taxis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>textclust</td>\n",
              "      <td>TrumpApproval</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         cluster           datasets\n",
              "0      CluStream  AirlinePassengers\n",
              "1       DBSTREAM            Bananas\n",
              "2      DenStream              Bikes\n",
              "3         KMeans       ChickWeights\n",
              "4   STREAMKMeans         CreditCard\n",
              "5      TextClust              Elec2\n",
              "6        __all__               HTTP\n",
              "7   __builtins__              Higgs\n",
              "8     __cached__      ImageSegments\n",
              "9        __doc__            Insects\n",
              "10      __file__          Keystroke\n",
              "11    __loader__       MaliciousURL\n",
              "12      __name__      MovieLens100K\n",
              "13   __package__              Music\n",
              "14      __path__           Phishing\n",
              "15      __spec__        Restaurants\n",
              "16     clustream            SMSSpam\n",
              "17      dbstream               SMTP\n",
              "18     denstream         SolarFlare\n",
              "19       k_means             TREC07\n",
              "20  streamkmeans              Taxis\n",
              "21     textclust      TrumpApproval"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "river_df[[\"cluster\",\"datasets\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugE8J7AT91X6",
        "outputId": "e41a15fa-7ddc-469b-b472-37f6aae3a88c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'empty_server_form_handler': 1.0, 'popup_window': 0.5, 'https': 1.0, 'request_from_other_domain': 1.0, 'anchor_from_other_domain': 1.0, 'is_popular': 0.5, 'long_url': 0.0, 'age_of_domain': 0, 'ip_in_url': 0}\n"
          ]
        }
      ],
      "source": [
        "from river import datasets\n",
        "dataset = datasets.Phishing()\n",
        "for x,y in dataset:\n",
        "  continue\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln-WsErDh1-1"
      },
      "source": [
        "**2.1 Clustering**\n",
        "<a id='cluster'></a>\n",
        "\n",
        "* CluStream\n",
        "\n",
        "* DBSTREAM\n",
        "\n",
        "* DenStream\n",
        "\n",
        "* KMeans\n",
        "\n",
        "* STREAMKMeans\n",
        "\n",
        "* TextClust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRFV2KRakQh0",
        "outputId": "a4362dd2-3167-49b5-9f5d-cce6d8547089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "river==0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep river\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s41qVRTgh07U",
        "outputId": "7ec6e073-af1d-4d86-f59c-e90abbeac0ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 1, 1: 2} 1 Silhouette\n",
            "{0: 1, 1: 4} 1 Silhouette\n",
            "{0: 1, 1: 0} 1 Silhouette\n",
            "{0: 4, 1: 2} 1 Silhouette\n",
            "{0: 4, 1: 4} 1 Silhouette\n",
            "{0: 4, 1: 0} 1 Silhouette\n",
            "{0: -2, 1: 2} 2 Silhouette\n",
            "{0: -2, 1: 4} 2 Silhouette\n",
            "{0: -2, 1: 0} 2 Silhouette\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X = [\n",
        "     [1, 2],\n",
        "     [1, 4],\n",
        "     [1, 0],\n",
        "     [4, 2],\n",
        "     [4, 4],\n",
        "     [4, 0],\n",
        "     [-2, 2],\n",
        "     [-2, 4],\n",
        "     [-2, 0]\n",
        " ]\n",
        "\n",
        "k_means = cluster.KMeans(n_clusters=3, halflife=0.4, sigma=3, seed=0)\n",
        "metric = metrics.Silhouette()\n",
        "\n",
        "for x, _ in stream.iter_array(X):\n",
        "     k_means = k_means.learn_one(x)\n",
        "     y_pred = k_means.predict_one(x)\n",
        "     metric = metric.update(x, y_pred, k_means.centers)\n",
        "     print(x,y_pred,metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkP-VPc3mVZS"
      },
      "source": [
        "**2.2 Concept Drift**\n",
        "<a id='drift'></a>\n",
        "\n",
        "The concept drift problem means that probability distribution of the data changes unforeseenly and causes less accurate predictions over time. Batch processing techniques more likely to fail because the model already trained with different data But online learning methods continuously update themselves and they can detect concept drifting much earlier and may adapt themselves.\n",
        "\n",
        "* ADWIN\n",
        "* DDM\n",
        "* EDDM\n",
        "* HDDM_A\n",
        "* HDDM_W\n",
        "* KSWIN\n",
        "* PageHinkley\n",
        "* PeriodicTrigger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "VYkM9zot0xv9",
        "outputId": "f1a68b8c-db45-4f06-f8b6-799919686f9e"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'module' object is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/x5/pmx23w6j3gv_8q92knp288rr0000gq/T/ipykernel_99607/3888239489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdrifts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdrift_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Data is processed one sample at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdrift_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_detected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not iterable"
          ]
        }
      ],
      "source": [
        "\n",
        "drift_detector = drift.ADWIN\n",
        "drifts = []\n",
        "\n",
        "for i, val in enumerate(stream):\n",
        "    drift_detector.update(val)   # Data is processed one sample at a time\n",
        "    if drift_detector.change_detected():\n",
        "        # The drift detector indicates after each sample if there is a drift in the data\n",
        "        print(f'Change detected at index {i}')\n",
        "        drifts.append(i)\n",
        "\n",
        "plot_data(dist_a, dist_b, dist_c, drifts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJGXJwvH95Pt",
        "outputId": "307f3707-26e0-42c9-b0a1-6f34dbbf10da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.516 5.544\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable ADWIN object",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/x5/pmx23w6j3gv_8q92knp288rr0000gq/T/ipykernel_1766/3238063808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m      \u001b[0min_drift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_warning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madwin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0min_drift\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m          \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Change detected at index {i}, input value: {val}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable ADWIN object"
          ]
        }
      ],
      "source": [
        "\n",
        "adwin = ADWIN()\n",
        "\n",
        "# Simulate a data stream composed by two data distributions\n",
        "data_stream = np.concatenate((np.random.randint(2, size=1000),\n",
        "                               np.random.randint(4, high=8, size=1000)))\n",
        "\n",
        "# Update drift detector and verify if change is detected\n",
        "print(np.mean(data_stream[0:1000]),np.mean(data_stream[1000:len(data_stream)]))\n",
        "for i, val in enumerate(data_stream):\n",
        "     in_drift, in_warning = adwin.update(val)\n",
        "     if in_drift:\n",
        "         print(f\"Change detected at index {i}, input value: {val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIEG3MM4xYSP"
      },
      "source": [
        "**2.3 Build Pipeline**\n",
        "<a id='pipe'></a>\n",
        "\n",
        "Chain a sequence of operations and warrant reproducibility. \n",
        "* first n − 1 steps\n",
        "are transformers like scaler, bag of words, normalizer\n",
        "* last step can be a regressor, a classifier, a clusterer, a transformer \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VD-KN4LExeQm"
      },
      "outputs": [],
      "source": [
        "from river import linear_model, preprocessing\n",
        "model = (preprocessing.StandardScaler() |\n",
        "linear_model.LogisticRegression())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run CluStream on Keystroke Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = datasets.Keystroke()\n",
        "clustream = cluster.CluStream(\n",
        "n_macro_clusters=51,\n",
        "max_micro_clusters=60,\n",
        "time_gap=3,\n",
        "    seed=0,\n",
        "    halflife=0.4\n",
        ")\n",
        "predictions ={}\n",
        "actual = {}\n",
        "i=0\n",
        "for x, y in df:\n",
        "    clustream = clustream.learn_one(x)\n",
        "    predictions[i] = clustream.predict_one(x)\n",
        "    actual[i] = y\n",
        "    i = i+1\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate adjusted rand score "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.03547185007887272"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_dict={}\n",
        "k=0\n",
        "for i in sorted(set(actual.values())):\n",
        "    t_dict[i] = k\n",
        "    k= k+1\n",
        "actual_clusters=[]\n",
        "for i in actual.values():\n",
        "    actual_clusters.append(t_dict[i])\n",
        "adjusted_rand_score(actual_clusters,list(predictions.values()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run DenStream on SMTP dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smpt_dataset = datasets.SMTP()\n",
        "denstream = cluster.DenStream(decaying_factor=0.01,\n",
        "                               beta=0.5,\n",
        "                               mu=2.5,\n",
        "                               epsilon=0.5,\n",
        "                               n_samples_init=10)\n",
        "fp = 0\n",
        "tp = 0\n",
        "for x,y in smpt_dataset:\n",
        "    denstream = denstream.learn_one(x)\n",
        "    if denstream.predict_one(x) != y:\n",
        "        fp +=1\n",
        "    else:\n",
        "        tp +=1\n",
        "3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.04\n",
            "95126 30\n"
          ]
        }
      ],
      "source": [
        "t_dict={}\n",
        "k=0\n",
        "for i in sorted(set(actual.values())):\n",
        "    t_dict[i] = k\n",
        "    k= k+1\n",
        "actual_clusters=[]\n",
        "for i in actual.values():\n",
        "    actual_clusters.append(t_dict[i])\n",
        "print(format(adjusted_rand_score(list(predictions.values()),actual_clusters),\".2f\"))\n",
        "print(tp,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run Clustream on SMTP dataset and calculate fp,tp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "523 94633\n"
          ]
        }
      ],
      "source": [
        "clustream = cluster.CluStream(\n",
        "n_macro_clusters=2,\n",
        "max_micro_clusters=2,\n",
        "time_gap=100,\n",
        "    seed=0,\n",
        "    halflife=0.4\n",
        ")\n",
        "fp = 0\n",
        "tp = 0\n",
        "for x,y in smpt_dataset:\n",
        "    clustream = clustream.learn_one(x)\n",
        "    if clustream.predict_one(x) != y:\n",
        "        fp +=1\n",
        "    else:\n",
        "        tp +=1\n",
        "print(tp,fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtBSbCfahEll"
      },
      "source": [
        "**References**\n",
        "\n",
        "\n",
        "1.   https://github.com/online-ml/river/blob/main/river/cluster/k_means.py\n",
        "2.   https://dl.acm.org/doi/10.1145/3534678.3542600\n",
        "3.   https://www.section.io/engineering-education/online-machine-learning-with-river-python/#river-python-installation\n",
        "4.   https://www.youtube.com/watch?v=nzFTmJnIakk\n",
        "5.   https://riverml.xyz/0.14.0/\n",
        "6.   https://www.jmlr.org/papers/volume22/20-1380/20-1380.pdf\n",
        "7.   https://dl.acm.org/doi/pdf/10.1145/3534678.3542600\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "15ead456faf89cb45219563e991a6bc4fe36c3dc076f4facfa18c447f4250216"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
